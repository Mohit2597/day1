 INSTALLATION OF HADOOP 
sudo yum install java-11-openjdk-devel
java -version
192.168.0.126
update-alternatives --config java

vi .bash_profile
export JAVA_HOME=/usr/lib/jvm/jre
source .bash_profile
echo JAVA_HOME

ssh-keygen -t rsa
 scp id_rsa.pub hadoop@192.168.0.126:/home/hadoo/.ssh
 chmod 700 .ssh
 chmod 600 .ssh/authorized_keys
 mv id_rsa.pub authorized_keys
sudo systemctl restart sshd.service

scp hadoop-3.3.0-aarch64.tar ec2-user@15.207.98.178.166:/home/ec2-user
tar zvf hadoop-3.3.0-aarch64.tar
mkdir -p /opt/hadoop
mv hadoop-3.3.0/* /opt/hadoop
chown -R hadoop:hadoop /opt/hadoop
ls /opt/hadoop
su - hadoop

$vi .bash_profile
    export JAVA_HOME=/usr/lib/jvm/jre
    export PATH=$PATH:$JAVA_HOME/bin
    export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/jre/lib/tools.jar
    export HADOOP_HOME=/opt/hadoop
    export HADOOP_INSTALL=$HADOOP_HOME
    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME
    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
$source .bash_profile
$echo $JAVA_HOME
$echo $HADOOP_HOME
$ls $HADOOP_HOME/etc/hadoop


2. CONFIGURATION OF HADOOP

cd $HADOOP_HOME/etc/hadoop/
		vi hadoop-env.sh
		export JAVA_HOME=${JAVA_HOME} ====   export JAVA_HOME=/usr/lib/jvm/jre

vi core-site.xml
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>

vi hdfs-site.xml
	<name>dfs.replication</name>
	<value>1</value>

vi mapred-site.xml
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
		<name>mapreduce.application.classpath</name>
		<value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>
	</property>

vi yarn-site.xml
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>yarn</value>
	</property>
	<property>
		<name>mapreduce.application.classpath</name>
		<value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>
	</property>

$ hdfs namenode -format
$ cd $HADOOP_HOME/sbin
$ start-dfs.sh
$ start-yarn.sh
$jps


    http://15.207.98.178:50070
    http://15.207.98.178:8088
    http://15.207.98.178:8042
    http://15.207.98.178:50095






user@PC:~$ rm -rf .ssh/*
user@PC:~$ ssh-keygen -t rsa > /dev/null 
Enter file in which to save the key (/home/user/.ssh/id_rsa): 
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
user@PC:~$ ls .ssh/
id_rsa  id_rsa.pub
user@PC:~$ ssh-copy-id -i localhost 
The authenticity of host 'localhost (::1)' can't be established.
RSA key fingerprint is f7:87:b5:4e:31:a1:72:11:8e:5f:d2:61:bd:b3:40:1a.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'localhost' (RSA) to the list of known hosts.







